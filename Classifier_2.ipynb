{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wczytywanie danych\n",
    "\n",
    "# dir_path = os.path.dirname(os.path.realpath(__file__))\n",
    "training_set = datasets.load_files(\"training_set\", encoding=\"utf-8\", random_state=420) \n",
    "# random_state miesza dane, wartość to seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'niedbal wyspa ogorzały ręka trzymać lejka i odwracać twarz wieźć przez kobieta odpowiadać wesoły zapytanie i przycinek czas męski śmiech swój łączyć ezyt chór cienki piskliwy śmiech dziewczę'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# przydatne atrybuty\n",
    "\n",
    "# training_set.filenames\n",
    "# training_set.data\n",
    "# training_set.target_names\n",
    "# training_set.target\n",
    "# training_set.target_names[training_set.target[3]]\n",
    "training_set.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1094, 3583)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenizacja\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vect = CountVectorizer()\n",
    "train_count_vectors = count_vect.fit_transform(training_set.data)\n",
    "train_count_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 3061)\t1\n",
      "  (0, 494)\t1\n",
      "  (0, 2376)\t1\n",
      "  (0, 2156)\t1\n",
      "  (0, 2487)\t1\n",
      "  (0, 3422)\t1\n",
      "  (0, 1186)\t1\n",
      "  (0, 2378)\t1\n",
      "  (0, 3525)\t1\n",
      "  (0, 1673)\t1\n",
      "  (0, 3180)\t1\n",
      "  (0, 2591)\t1\n",
      "  (0, 714)\t1\n",
      "  (0, 2806)\t1\n",
      "  (0, 349)\t1\n",
      "  (0, 2776)\t1\n",
      "  (0, 1170)\t1\n",
      "  (0, 2738)\t1\n"
     ]
    }
   ],
   "source": [
    "# count_vect.vocabulary_.get('koń') # liczba wystąpień słowa w całym zbiorze\n",
    "# print(train_count_vectors[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x3583 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 25 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tf–idf - “Term Frequency times Inverse Document Frequency”\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "#fit our estimator to the data and transform our count-matrix to a tf-idf representation\n",
    "train_tfidf = tfidf_transformer.fit_transform(train_count_vectors) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training a classifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "classifier = MultinomialNB().fit(train_tfidf, training_set.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Dlaczego z gorącego snu pierwszej młodości obudziła się nie tylko samotna i smutna, ale zarazem obrażona i z niewyschłą dotąd kroplą goryczy w sercu?' => P\n",
      "'Pod złotawym, a potem już siwiejącym wąsem zawsze purpurowe, zmysłowe jego usta układały się w wyraz lubości, ilekroć zobaczył jakąkolwiek ładną twarzyczkę lub zgrabną kibić niewieścią.' => P\n",
      "'Przed sobą, o kroków kilkanaście, zobaczyła wznoszącą się nad zbożem, rozłożystą i całą w słońcu stojącą gruszę polną; pień, gałęzie i wszystkie liście tego drzewa były złote' => P\n",
      "'Był to wraz z brzegiem rzeki zginający się nieco w półkole sznur siedlisk ludzkich, większych i mniejszych, wychylających ciemne swe profile z większych i mniejszych ogrodów.' => P\n"
     ]
    }
   ],
   "source": [
    "# takie sobie testy zdań\n",
    "test_data = ['Dlaczego z gorącego snu pierwszej młodości obudziła się nie tylko samotna i smutna, ale zarazem obrażona i z niewyschłą dotąd kroplą goryczy w sercu?', \n",
    "             'Pod złotawym, a potem już siwiejącym wąsem zawsze purpurowe, zmysłowe jego usta układały się w wyraz lubości, ilekroć zobaczył jakąkolwiek ładną twarzyczkę lub zgrabną kibić niewieścią.',\n",
    "            'Przed sobą, o kroków kilkanaście, zobaczyła wznoszącą się nad zbożem, rozłożystą i całą w słońcu stojącą gruszę polną; pień, gałęzie i wszystkie liście tego drzewa były złote',\n",
    "            'Był to wraz z brzegiem rzeki zginający się nieco w półkole sznur siedlisk ludzkich, większych i mniejszych, wychylających ciemne swe profile z większych i mniejszych ogrodów.']\n",
    "X_new_counts = count_vect.transform(test_data)\n",
    "X_new_tfidf = tfidf_transformer.transform(X_new_counts)\n",
    "\n",
    "predicted = classifier.predict(X_new_tfidf)\n",
    "\n",
    "for doc, category in zip(test_data, predicted):\n",
    "     print('%r => %s' % (doc, training_set.target_names[category]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8226691042047533\n"
     ]
    }
   ],
   "source": [
    "# Tworzenie Naive Bayes Clf w pipeline i trenowanie\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "\n",
    "clf = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultinomialNB()),\n",
    "])\n",
    "\n",
    "training_set = datasets.load_files(\"training_set\", encoding=\"utf-8\", random_state=420) \n",
    "clf.fit(training_set.data, training_set.target)\n",
    "\n",
    "# NotFittedError: CountVectorizer - Vocabulary wasn't fitted. - nwm co jest nie tak\n",
    "test_set = training_set.data\n",
    "predicted = clf.predict(test_set)\n",
    "print(np.mean(predicted == training_set.target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8226691042047533\n"
     ]
    }
   ],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# test_set = training_set.data\n",
    "# X_new_counts = count_vect.transform(test_set)\n",
    "# X_new_tfidf = tfidf_transformer.transform(X_new_counts)\n",
    "\n",
    "# predicted = classifier.predict(X_new_tfidf)\n",
    "# print(np.mean(predicted == training_set.target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.00      0.00      0.00        34\n",
      "           O       1.00      0.05      0.10       169\n",
      "           P       0.82      1.00      0.90       891\n",
      "\n",
      "   micro avg       0.82      0.82      0.82      1094\n",
      "   macro avg       0.61      0.35      0.33      1094\n",
      "weighted avg       0.82      0.82      0.75      1094\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\mike\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(training_set.target, predicted, target_names=training_set.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9986842105263158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\mike\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# # Tworzenie SVM Clf w pipeline i trenowanie\n",
    "from sklearn import datasets\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "\n",
    "svm_clf = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', SGDClassifier(loss='hinge', penalty='l2', alpha=1e-4, random_state=420,\n",
    "                          max_iter=5, tol=None)),\n",
    "])\n",
    "\n",
    "training_set = datasets.load_files(\"training_set\", encoding=\"utf-8\", random_state=420)\n",
    "svm_clf.fit(training_set.data, training_set.target)\n",
    "\n",
    "test_set = training_set.data\n",
    "predicted = svm_clf.predict(test_set)\n",
    "print(np.mean(predicted == training_set.target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       1.00      1.00      1.00       144\n",
      "           O       1.00      0.99      0.99       196\n",
      "           P       1.00      1.00      1.00      1180\n",
      "\n",
      "   micro avg       1.00      1.00      1.00      1520\n",
      "   macro avg       1.00      1.00      1.00      1520\n",
      "weighted avg       1.00      1.00      1.00      1520\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(training_set.target, predicted, target_names=training_set.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search dls SVM\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# parameters = {\n",
    "#     # parametry CountVectorizer\n",
    "#     \"\"\"...CountVectorizer(*, input='content', encoding='utf-8', decode_error='strict', \n",
    "#     strip_accents=None, lowercase=True, preprocessor=None, tokenizer=None, stop_words=None, token_pattern='(?u)\\b\\w\\w+\\b', \n",
    "#     ngram_range=(1, 1), analyzer='word', max_df=1.0, min_df=1, max_features=None, vocabulary=None, binary=False, \n",
    "#     dtype=<class 'numpy.int64'>)\"\"\"\n",
    "#     'vect__decode_error': ('strict', 'ignore', 'replace'),\n",
    "#     'vect__ngram_range': [(1, 1), (1, 2), (2, 2)], # (1, 1), (1, 2), (2, 2), (2, 3), (3, 3) \n",
    "#     'vect__max_df': [1.0, 0.90, 0.80, 0.70], # 1.0, 0.95, 0.90, 0.85, 0.80, 0.75, 0.70\n",
    "#     'vect__min_df': [1, 0.10, 0.20, 0.30] # 0.05, 0.10, 0.15, 0.20, 0.25, 0.30\n",
    "    \n",
    "#     # parametry TfidfTransformer\n",
    "#     \"\"\"...TfidfTransformer(*, norm='l2', use_idf=True, smooth_idf=True, sublinear_tf=False)\"\"\"\n",
    "#     #można coś jeszcze dodać niby, ale to chyba takie szczegóły, że nie ma sensu\n",
    "#     'tfidf__use_idf': (True, False),\n",
    "    \n",
    "#     # parametry SGDClassifier (SVM)\n",
    "#     \"\"\"SGDClassifier(loss='hinge', *, penalty='l2', alpha=0.0001, l1_ratio=0.15, fit_intercept=True, max_iter=1000, \n",
    "#     tol=0.001, shuffle=True, verbose=0, epsilon=0.1, n_jobs=None, random_state=None, learning_rate='optimal', eta0=0.0, \n",
    "#     power_t=0.5, early_stopping=False, validation_fraction=0.1, n_iter_no_change=5, class_weight=None, warm_start=False, \n",
    "#     average=False)\"\"\"\n",
    "#     \"\"\"'clf__loss': The possible options are ‘hinge’, ‘log’, ‘modified_huber’, ‘squared_hinge’, ‘perceptron’, or a \n",
    "#     regression loss: ‘squared_loss’, ‘huber’, ‘epsilon_insensitive’, or ‘squared_epsilon_insensitive’.\n",
    "#     Trochę dużo tego \"\"\"\n",
    "#     'clf__alpha': (1e-2, 1e-3, 1e-4),\n",
    "#     'clf__shuffle': (True, False),\n",
    "#     'clf__class_weight': (None, 'balanced')     \n",
    "# }\n",
    "\n",
    "\n",
    "parameters = {\n",
    "    'vect__decode_error': ('replace',), # ('strict', 'ignore', 'replace')\n",
    "    'vect__ngram_range': [(1, 2),(2, 2), (2, 3), (3, 3)], # (1, 1), (1, 2), (2, 2), (2, 3), (3, 3) \n",
    "    'vect__max_df': [1.0, 0.95, 0.90], # 1.0, 0.95, 0.90, 0.85, 0.80, 0.75, 0.70\n",
    "    'vect__min_df': [2, 1, 0], # 0.05, 0.10, 0.15, 0.20, 0.25, 0.30 \n",
    "    'vect__binary': (False,True),\n",
    "    'tfidf__use_idf': (True,), # zawsze wychodzi True\n",
    "    'tfidf__norm': ('l1','l2'),\n",
    "    'tfidf__sublinear_tf': (False, True),\n",
    "    # można dodać jeszcze kilka parametrów tfidf niby, ale to chyba takie szczegóły, że nie ma sensu\n",
    "    'clf__alpha': (1e-3, 1e-4, 1e-5),\n",
    "    'clf__shuffle': (True,), # (True, False)\n",
    "    'clf__class_weight': (None, 'balanced'), # możemy chcieć None, bo mała część przykładów jest z klasy N\n",
    "    'clf__penalty': ('l1','l2'), #('l1','l2')\n",
    "#     'clf__loss': ('hinge', 'log', 'modified_huber')\n",
    "#     ('hinge', 'log', 'modified_huber', 'squared_hinge', 'perceptron', 'squared_loss', 'huber', \n",
    "#       'epsilon_insensitive', 'squared_epsilon_insensitive')\n",
    "}\n",
    "\n",
    "grid_search_clf = GridSearchCV(svm_clf, parameters, cv=5, n_jobs=3) # !!! n_jobs - LICZBA UŻYWANYCH RDZENI !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\mike\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "c:\\users\\mike\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "grid_search_clf = grid_search_clf.fit(training_set.data, training_set.target)\n",
    "# grid_search_clf.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8322368421052632\n",
      "clf__alpha: 0.0001\n",
      "clf__class_weight: 'balanced'\n",
      "clf__loss: 'hinge'\n",
      "clf__penalty: 'l2'\n",
      "clf__shuffle: True\n",
      "tfidf__norm: 'l2'\n",
      "tfidf__sublinear_tf: False\n",
      "tfidf__use_idf: True\n",
      "vect__binary: True\n",
      "vect__decode_error: 'replace'\n",
      "vect__max_df: 1.0\n",
      "vect__min_df: 1\n",
      "vect__ngram_range: (1, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n0.8546617915904936\\nclf__alpha: 0.001\\nclf__class_weight: 'balanced'\\nclf__penalty: 'l2'\\nclf__shuffle: True\\ntfidf__use_idf: True\\nvect__binary: True\\nvect__decode_error: 'strict'\\nvect__max_df: 1.0\\nvect__min_df: 1\\nvect__ngram_range: (1, 2)\\n\\n\\n0.8208409506398537\\nclf__alpha: 0.0001\\nclf__class_weight: None\\nclf__penalty: 'l2'\\nclf__shuffle: True\\ntfidf__norm: 'l2'\\ntfidf__sublinear_tf: False\\ntfidf__use_idf: True\\nvect__binary: False\\nvect__decode_error: 'replace'\\nvect__max_df: 1.0\\nvect__min_df: 1\\nvect__ngram_range: (2, 2) # nie było opcji (1, 2)\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(grid_search_clf.best_score_)\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"%s: %r\" % (param_name, grid_search_clf.best_params_[param_name]))\n",
    "    \n",
    "\"\"\"\n",
    "0.8546617915904936\n",
    "clf__alpha: 0.001\n",
    "clf__class_weight: 'balanced'\n",
    "clf__penalty: 'l2'\n",
    "clf__shuffle: True\n",
    "tfidf__use_idf: True\n",
    "vect__binary: True\n",
    "vect__decode_error: 'strict'\n",
    "vect__max_df: 1.0\n",
    "vect__min_df: 1\n",
    "vect__ngram_range: (1, 2)\n",
    "\n",
    "\n",
    "0.8208409506398537\n",
    "clf__alpha: 0.0001\n",
    "clf__class_weight: None\n",
    "clf__penalty: 'l2'\n",
    "clf__shuffle: True\n",
    "tfidf__norm: 'l2'\n",
    "tfidf__sublinear_tf: False\n",
    "tfidf__use_idf: True\n",
    "vect__binary: False\n",
    "vect__decode_error: 'replace'\n",
    "vect__max_df: 1.0\n",
    "vect__min_df: 1\n",
    "vect__ngram_range: (2, 2) # nie było opcji (1, 2)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8208409506398537\n",
      "clf__alpha: 0.0001\n",
      "clf__class_weight: None\n",
      "clf__penalty: 'l2'\n",
      "clf__shuffle: True\n",
      "tfidf__norm: 'l2'\n",
      "tfidf__sublinear_tf: False\n",
      "tfidf__use_idf: True\n",
      "vect__binary: False\n",
      "vect__decode_error: 'replace'\n",
      "vect__max_df: 1.0\n",
      "vect__min_df: 1\n",
      "vect__ngram_range: (2, 2)\n"
     ]
    }
   ],
   "source": [
    "print(grid_search_clf.best_score_)\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"%s: %r\" % (param_name, grid_search_clf.best_params_[param_name]))\n",
    "    \n",
    "\"\"\"\n",
    "0.8208409506398537\n",
    "clf__alpha: 0.0001\n",
    "clf__class_weight: None\n",
    "clf__penalty: 'l2'\n",
    "clf__shuffle: True\n",
    "tfidf__norm: 'l2'\n",
    "tfidf__sublinear_tf: False\n",
    "tfidf__use_idf: True\n",
    "vect__binary: False\n",
    "vect__decode_error: 'replace'\n",
    "vect__max_df: 1.0\n",
    "vect__min_df: 1\n",
    "vect__ngram_range: (2, 2)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P\n"
     ]
    }
   ],
   "source": [
    "# 'Był to wraz z brzegiem rzeki zginający się nieco w półkole sznur siedlisk ludzkich, większych i mniejszych, wychylających ciemne swe profile z większych i mniejszych ogrodów.'\n",
    "tag = grid_search_clf.predict(['drzewo ogórd słońce las kwiat'])[0]\n",
    "print(training_set.target_names[tag])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9986842105263158\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       1.00      1.00      1.00       144\n",
      "           O       0.99      1.00      0.99       196\n",
      "           P       1.00      1.00      1.00      1180\n",
      "\n",
      "   micro avg       1.00      1.00      1.00      1520\n",
      "   macro avg       1.00      1.00      1.00      1520\n",
      "weighted avg       1.00      1.00      1.00      1520\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\mike\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "0.8322368421052632\n",
    "clf__alpha: 0.0001\n",
    "clf__class_weight: 'balanced'\n",
    "clf__loss: 'hinge'\n",
    "clf__penalty: 'l2'\n",
    "clf__shuffle: True\n",
    "tfidf__norm: 'l2'\n",
    "tfidf__sublinear_tf: False\n",
    "tfidf__use_idf: True\n",
    "vect__binary: True\n",
    "vect__decode_error: 'replace'\n",
    "vect__max_df: 1.0\n",
    "vect__min_df: 1\n",
    "vect__ngram_range: (1, 2)\n",
    "\"\"\"\n",
    "# # Tworzenie SVM Clf w pipeline i trenowanie\n",
    "from sklearn import datasets\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "\n",
    "svm_clf = Pipeline([\n",
    "    ('vect', CountVectorizer(binary=True, decode_error='replace', max_df=1.0, min_df=1, ngram_range=(1, 2))),\n",
    "    ('tfidf', TfidfTransformer(norm='l2', sublinear_tf=False, use_idf=True)),\n",
    "    ('clf', SGDClassifier(loss='hinge', penalty='l2', alpha=1e-4, class_weight='balanced', random_state=420,\n",
    "                          shuffle=True)),\n",
    "])\n",
    "\n",
    "training_set = datasets.load_files(\"training_set\", encoding=\"utf-8\", random_state=420)\n",
    "svm_clf.fit(training_set.data, training_set.target)\n",
    "\n",
    "test_set = training_set.data\n",
    "predicted = svm_clf.predict(test_set)\n",
    "print(np.mean(predicted == training_set.target))\n",
    "\n",
    "from sklearn import metrics\n",
    "print(metrics.classification_report(training_set.target, predicted, target_names=training_set.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('svm_clf.pickle', 'wb') as f:\n",
    "    pickle.dump(svm_clf, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N\n"
     ]
    }
   ],
   "source": [
    "# del svm_clf\n",
    "\n",
    "with open('svm_clf.pickle', 'rb') as f:\n",
    "    loaded_svm_clf = pickle.load(f)\n",
    "    \n",
    "tag = loaded_svm_clf.predict(['drzewo ogórd słońce las kwiat'])[0]\n",
    "print(training_set.target_names[tag])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Dlaczego z gorącego snu pierwszej młodości obudziła się nie tylko samotna i smutna, ale zarazem obrażona i z niewyschłą dotąd kroplą goryczy w sercu?' => P\n",
      "'Pod złotawym, a potem już siwiejącym wąsem zawsze purpurowe, zmysłowe jego usta układały się w wyraz lubości, ilekroć zobaczył jakąkolwiek ładną twarzyczkę lub zgrabną kibić niewieścią.' => O\n",
      "'Przed sobą, o kroków kilkanaście, zobaczyła wznoszącą się nad zbożem, rozłożystą i całą w słońcu stojącą gruszę polną; pień, gałęzie i wszystkie liście tego drzewa były złote' => P\n",
      "'Był to wraz z brzegiem rzeki zginający się nieco w półkole sznur siedlisk ludzkich, większych i mniejszych, wychylających ciemne swe profile z większych i mniejszych ogrodów.' => P\n"
     ]
    }
   ],
   "source": [
    "# training_set.target_names\n",
    "target_names = ['N', 'O', 'P']\n",
    "\n",
    "test_data = ['Dlaczego z gorącego snu pierwszej młodości obudziła się nie tylko samotna i smutna, ale zarazem obrażona i z niewyschłą dotąd kroplą goryczy w sercu?', \n",
    "             'Pod złotawym, a potem już siwiejącym wąsem zawsze purpurowe, zmysłowe jego usta układały się w wyraz lubości, ilekroć zobaczył jakąkolwiek ładną twarzyczkę lub zgrabną kibić niewieścią.',\n",
    "            'Przed sobą, o kroków kilkanaście, zobaczyła wznoszącą się nad zbożem, rozłożystą i całą w słońcu stojącą gruszę polną; pień, gałęzie i wszystkie liście tego drzewa były złote',\n",
    "            'Był to wraz z brzegiem rzeki zginający się nieco w półkole sznur siedlisk ludzkich, większych i mniejszych, wychylających ciemne swe profile z większych i mniejszych ogrodów.']\n",
    "\n",
    "predicted = loaded_svm_clf.predict(test_data)\n",
    "\n",
    "for doc, category in zip(test_data, predicted):\n",
    "     print('%r => %s' % (doc, target_names[category]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Dlaczego z gorącego snu pierwszej młodości obudziła się nie tylko samotna i smutna, ale zarazem obrażona i z niewyschłą dotąd kroplą goryczy w sercu?' => P\n",
      "'Pod złotawym, a potem już siwiejącym wąsem zawsze purpurowe, zmysłowe jego usta układały się w wyraz lubości, ilekroć zobaczył jakąkolwiek ładną twarzyczkę lub zgrabną kibić niewieścią.' => O\n",
      "'Przed sobą, o kroków kilkanaście, zobaczyła wznoszącą się nad zbożem, rozłożystą i całą w słońcu stojącą gruszę polną; pień, gałęzie i wszystkie liście tego drzewa były złote' => P\n",
      "'Był to wraz z brzegiem rzeki zginający się nieco w półkole sznur siedlisk ludzkich, większych i mniejszych, wychylających ciemne swe profile z większych i mniejszych ogrodów.' => P\n",
      "N\n"
     ]
    }
   ],
   "source": [
    "#kod do skryptu całego programu\n",
    "from sklearn import datasets\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "\n",
    "with open('svm_clf.pickle', 'rb') as f:\n",
    "    svm_clf = pickle.load(f)\n",
    "    \n",
    "    target_names = ['N', 'O', 'P']\n",
    "\n",
    "    # klasyfikacja 1\n",
    "    test_data = ['Dlaczego z gorącego snu pierwszej młodości obudziła się nie tylko samotna i smutna, ale zarazem obrażona i z niewyschłą dotąd kroplą goryczy w sercu?', \n",
    "                 'Pod złotawym, a potem już siwiejącym wąsem zawsze purpurowe, zmysłowe jego usta układały się w wyraz lubości, ilekroć zobaczył jakąkolwiek ładną twarzyczkę lub zgrabną kibić niewieścią.',\n",
    "                'Przed sobą, o kroków kilkanaście, zobaczyła wznoszącą się nad zbożem, rozłożystą i całą w słońcu stojącą gruszę polną; pień, gałęzie i wszystkie liście tego drzewa były złote',\n",
    "                'Był to wraz z brzegiem rzeki zginający się nieco w półkole sznur siedlisk ludzkich, większych i mniejszych, wychylających ciemne swe profile z większych i mniejszych ogrodów.']\n",
    "\n",
    "    predicted = svm_clf.predict(test_data) # zwraca id klas; target_names[id] - nazwa klasy\n",
    "\n",
    "    for doc, category in zip(test_data, predicted):\n",
    "         print('%r => %s' % (doc, target_names[category]))\n",
    "\n",
    "    # klasyfikacja 2\n",
    "    tag = svm_clf.predict(['drzewo ogórd słońce las kwiat'])[0]\n",
    "    print('drzewo ogórd słońce las kwiat => '+target_names[tag])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
